<!DOCTYPE html>
<html>
  <head>
	<!--  <meta name = "viewport" content = "user-scalable=no,width=device-width"> -->
	
    <link href = "style.css" rel = "stylesheet" type = "">
    <title>Capture The Flipping Flag</title>

	<script type = "text/javascript">	
		var needResize = false;
		let sources = ["display", "game", "engine", "controller", "decibel-meter","main"];
		
		for (let index = 0; index < sources.length; index ++) {
			let script = document.createElement("script");
			script.setAttribute("type", "text/javascript");
			script.setAttribute("src", String(sources[index] + ".js"));
			document.head.appendChild(script);
		}
		function closeButton(){
			needResize = true;
		};
		
		function Microphone(_fft){
			var FFT_SIZE = _fft || 1024;
			this.spectrum = [];
			 this.volume = this.vol = 0;
  this.peak_volume = 0;
    var self = this;
  var audioContext = new AudioContext();
  var SAMPLE_RATE = audioContext.sampleRate;
  
  // this is just a browser check to see
  // if it supports AudioContext and getUserMedia
  window.AudioContext = window.AudioContext ||  window.webkitAudioContext;
  navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia;
  window.addEventListener('load', init, false);
   function init () {
      try {
        startMic(new AudioContext());
      }
      catch (e) {
        console.error(e);
        alert('Web Audio API is not supported in this browser');
      }
  }
  function startMic (context) {
    navigator.getUserMedia({ audio: true }, processSound, error);
	    function processSound (stream) {
		  // analyser extracts frequency, waveform, etc.
			 var analyser = context.createAnalyser();
			 analyser.smoothingTimeConstant = 0.2;
			 analyser.fftSize = FFT_SIZE;
			  var node = context.createScriptProcessor(FFT_SIZE*2, 1, 1);
			  node.onaudioprocess = function () {
			   self.spectrum = new Uint8Array(analyser.frequencyBinCount);
			   // getByteFrequencyData returns amplitude for each bin
       analyser.getByteFrequencyData(self.spectrum);
       // getByteTimeDomainData gets volumes over the sample time
       // analyser.getByteTimeDomainData(self.spectrum);

       self.vol = self.getRMS(self.spectrum);
       // get peak - a hack when our volumes are low
       if (self.vol > self.peak_volume) self.peak_volume = self.vol;
       self.volume = self.vol;
	        };
			 var input = context.createMediaStreamSource(stream);
     input.connect(analyser);
     analyser.connect(node);
     node.connect(context.destination);
	 }
	   function error () {
     console.log(arguments);
  }
  }return this;};
  var Mic = new Microphone();
  this.getRMS = function (spectrum) {
  var rms = 0;
  for (var i = 0; i < vols.length; i++) {
    rms += spectrum[i] * spectrum[i];
  }
  rms /= spectrum.length;
  rms = Math.sqrt(rms);
  return rms;
 }		
			
			
			
		// document.addEventListener('click', musicPlay);
		// function musicPlay() {
		// 	document.getElementById('audio').play();
		// 	document.removeEventListener('click', musicPlay);
		// }
	</script>
	
	
  </head>
  
  <body>
		<div id="message">Click mic to toggle listening</div>
		<div id="meter" class="icon-microphone"><span></span></div>
	  <p id = "db-level">ff</p>
	  <div id="main">
		  <div id = "canvasContainer" >
			  <canvas id="canvas"></canvas>
			</div>
	  </div>

	<audio autoplay loop id="audio"><source src="sounds/open_air.mp3" type="audio/mpeg"></audio>
	<p>Open Air for Those Who Don't by Tom_Ena (c) copyright 2010 Licensed under a Creative Commons Sampling Plus license. http://dig.ccmixter.org/files/Tom_Ena/29151 Ft: The Orchestral Movement of 1932</p>
	<div id="dummy" style="display:none"></div>
  </body>

</html> 